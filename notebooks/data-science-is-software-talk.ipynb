{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; border: 0px solid black;\">\n",
    "    <tr style=\"width: 100%; border: 0px solid black;\">\n",
    "        <td style=\"width:75%; border: 0px solid black;\">\n",
    "            <a href=\"http://www.drivendata.org\">\n",
    "                <img src=\"https://s3.amazonaws.com/drivendata.org/kif-example/img/dd.png\" />\n",
    "            </a>\n",
    "        </td>\n",
    "        <td style=\"width:20%; border: 0px solid black;\">\n",
    "            <strong>Peter Bull</strong> <br>\n",
    "            <strong>Data Scientist</strong> <br>\n",
    "            <a target=_blank href=\"http://www.drivendata.org\">DrivenData</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science is Software: Developer #lifehacks for the Jupyter Data Scientist\n",
    "\n",
    "21 May 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. This is my house\n",
    "\n",
    "### Environment reproducibility for Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 The [watermark](https://github.com/rasbt/watermark) extension\n",
    "\n",
    "Tell everyone when your notebook was run, and with which packages. This is especially useful for nbview, blog posts, and other media where you are not sharing the notebook as executable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# install the watermark extension\n",
    "!pip install watermark\n",
    "\n",
    "# once it is installed, you'll just need this in future notebooks:\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%watermark -a \"Peter Bull\" -d -v -p numpy,pandas -g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Laying the foundation\n",
    "\n",
    "[`virtualenv`](https://virtualenv.pypa.io/en/latest/installation.html) and [`virtualenvwrapper`](http://virtualenvwrapper.readthedocs.org/en/latest/#) give you a new foundation.\n",
    "\n",
    " - Start from \"scratch\" on each project\n",
    " - Choose Python 2 or 3 as appropriate\n",
    " - Packages are cached locally, so no need to wait for download/compile on every new env\n",
    " \n",
    "Installation is as easy as:\n",
    " - `pip install virtualenv`\n",
    " - `pip install virtualenvwrapper`\n",
    " - Add the following lines to `~/.bashrc`:\n",
    " \n",
    "------\n",
    "\n",
    "```\n",
    "export WORKON_HOME=$HOME/.virtualenvs\n",
    "export PROJECT_HOME=$HOME/Devel\n",
    "source /usr/local/bin/virtualenvwrapper.sh\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "To create a virtual environment:\n",
    "\n",
    " - `mkvirtualenv <name>`\n",
    "\n",
    " \n",
    "To work in a particular virtual environment:\n",
    "\n",
    " - `workon <name>`\n",
    " \n",
    "To leave a virtual environment:\n",
    "\n",
    " - `deactivate`\n",
    " \n",
    " \n",
    "**`#lifehack`: create a new virtual environment for every project you work on**\n",
    "\n",
    "**`#lifehack`: if you use anaconda to manage packages using `mkvirtualenv --system-site-packages <name>` means you don't have to recompile large packages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.1 The `pip` [requirements.txt](https://pip.readthedocs.org/en/1.1/requirements.html) file\n",
    "\n",
    "Track your MRE, \"Minimum reproducible environment\" in a `requirements.txt` file\n",
    "\n",
    "**`#lifehack`: never again run `pip install <package>`. Instead, update `requirements.txt` and run `pip install -r requirements.txt`**\n",
    "\n",
    "**`#lifehack`: for data science projects, favor `package>=0.0.0` rather than `package==0.0.0`. This works well with the `--system-site-packages` flag so you don't have many versions of large packages with complex dependencies sitting around (e.g., numpy, scipy, pandas)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -n 20 ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Life-Changing Magic of Tidying Up\n",
    "\n",
    "## 2.1 Consistent project structure means\n",
    "\n",
    " - relative paths work\n",
    " - other collaborators know what to expect\n",
    " - order of scripts is self-documenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! tree .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Edit-run-repeat: how to stop the cycle of pain\n",
    "\n",
    "The goal: don't edit, execute and verify any more. How close can we get to code succeeding the first or second time you run it? It's a fine way to start a project, but it doesn't scale as code runs longer and gets more complex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 No more docs-guessing\n",
    "\n",
    "Don't edit-run-repeat to try to remember the name of a function or argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/water-pumps.csv\")\n",
    "df.head(1)\n",
    "\n",
    "## Try adding parameter index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/water-pumps.csv\",\n",
    "                 index_col=0,\n",
    "                 parse_dates=[\"date_recorded\"])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`#lifehack`: in addition to the `?` operator, the Jupyter notebooks has great intelligent code completion; try `tab` when typing the name of a function, try `shift+tab` when inside a method call **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 No more copy pasta\n",
    "\n",
    "Don't repeat yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data = df['construction_year']\n",
    "plot_data = plot_data[plot_data != 0]\n",
    "sns.kdeplot(plot_data, bw=0.1)\n",
    "plt.show()\n",
    "\n",
    "plot_data = df['longitude']\n",
    "plot_data = plot_data[plot_data != 0]\n",
    "sns.kdeplot(plot_data, bw=0.1)\n",
    "plt.show()\n",
    "\n",
    "## Paste for 'amount_tsh' and plot\n",
    "## Paste for 'latitude' and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kde_plot(dataframe, variable, upper=0.0, lower=0.0, bw=0.1):\n",
    "    plot_data = dataframe[variable]\n",
    "    plot_data = plot_data[(plot_data > lower) & (plot_data < upper)]\n",
    "    sns.kdeplot(plot_data, bw=bw)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kde_plot(df, 'construction_year', upper=2016)\n",
    "kde_plot(df, 'longitude', upper=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kde_plot(df, 'amount_tsh', upper=400000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 No more guess-and-check\n",
    "\n",
    "Interrupt execution with:\n",
    " - `%debug` magic: drops you out into _the most recent error stacktrace_ in pdb\n",
    " - `import q;q.d()`: drops you into pdb, even outside of IPython\n",
    " \n",
    "Interrupt execution on an Exception with `%pdb` magic. Use [pdb](https://docs.python.org/2/library/pdb.html) the Python debugger to debug inside a notebook.  Key commands for `pdb` are:\n",
    "\n",
    " - `p`: Evaluate and print Python code\n",
    " \n",
    " \n",
    " - `w`: Where in the stack trace am I?\n",
    " - `u`: Go up a frame in the stack trace.\n",
    " - `d`: Go down a frame in the stack trace.\n",
    " \n",
    " \n",
    " - `c`: Continue execution\n",
    " - `q`: Stop execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kde_plot(df, 'date_recorded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"1\" turns pdb on, \"0\" turns pdb off\n",
    "%pdb 1\n",
    "\n",
    "kde_plot(df, 'date_recorded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# turn off debugger\n",
    "%pdb 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`#lifehack`: %debug and %pdb are great, but pdb can be clunky. Try the 'q' module. Adding the line `import q;q.d()` anywhere in a project gives you a normal python console at that point. This is great if you're running outside of IPython. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 No more \"Restart & Run All\"\n",
    "\n",
    "`assert` is the poor man's unit test: stops execution if condition is `False`, continues silently if `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gimme_the_mean(series):\n",
    "    return np.mean(series)\n",
    "\n",
    "assert gimme_the_mean([0.0]*10) == 0.0\n",
    "assert gimme_the_mean(range(10)) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 No more copy-pasta between notebooks \n",
    "\n",
    "Have a method that gets used in multiple notebooks? Refactor it into a separate `.py` file so it can live a happy life!\n",
    "\n",
    "Note: In order to import your local modules, you must do three things:\n",
    "\n",
    " - put the .py file in a separate folder\n",
    " - add an empty `__init__.py` file to the folder\n",
    " - add that folder to the Python path with `sys.path.append`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my method from the source code\n",
    "from preprocess.build_features import remove_invalid_data\n",
    "\n",
    "df = remove_invalid_data(\"../data/water-pumps.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRY ADDING print \"lalalala\" to the method\n",
    "df = remove_invalid_data(\"../data/water-pumps.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the kernel, let's try this again...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my method from the source code\n",
    "%aimport preprocess.build_features\n",
    "from preprocess.build_features import remove_invalid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = remove_invalid_data(\"../data/water-pumps.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`#lifehack`: reloading modules in a running kernel is tricky business. If you use `%autoreload` when developing, restart the kernel and run all cells when you're done. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 I'm too good! Now this code is useful to other projects!\n",
    "\n",
    "Importing local code is great if you want to use it in multiple notebooks, but once you want to use the code in multiple projects or repositories, it gets complicated. This is when we get serious about isolation!\n",
    "\n",
    "We can build a python package to solve that! In fact, there is a [cookiecutter to create Python packages](https://github.com/kragniz/cookiecutter-pypackage-minimal).\n",
    "\n",
    "Once we create this package, we can install it in \"editable\" mode, which means that as we change the code the changes will get picked up if the package is used. The process looks like\n",
    "\n",
    "    cookiecutter https://github.com/kragniz/cookiecutter-pypackage-minimal\n",
    "    cd package_name\n",
    "    pip install -e .\n",
    "    \n",
    "Now we can have a separate repository for this code and it can be used across projects without having to maintain code in multiple places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 No more letting other people (including future you) break your toys\n",
    "\n",
    "`unittest` is a unit testing framework that is built in to Python. See `src/preprocess/tests.py` for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ../src/preprocess/tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`#lifehack`: test your code. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Special treats for datascience testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `numpy.testing`\n",
    "Provides useful assertion methods for values that are numerically close and for numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.random.normal(0.0, 1.0, 1000000)\n",
    "assert gimme_the_mean(data) == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(gimme_the_mean(data),\n",
    "                               0.0,\n",
    "                               decimal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.normal(0, 0.0001, 10000)\n",
    "b = np.random.normal(0, 0.0001, 10000)\n",
    "\n",
    "np.testing.assert_array_equal(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.testing.assert_array_almost_equal(a, b, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [engarde]() decorators\n",
    "\n",
    "A new library that lets you practice defensive program--specifically with pandas `DataFrame` objects. It provides a set of decorators that check the return value of any function that returns a `DataFrame` and confirms that it conforms to the rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import engarde.decorators as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame({'a': np.random.normal(0, 1, 100),\n",
    "                          'b': np.random.normal(0, 1, 100)})\n",
    "\n",
    "@ed.none_missing()\n",
    "def process(dataframe):\n",
    "    dataframe.loc[10, 'a'] = np.nan\n",
    "    return dataframe\n",
    "\n",
    "process(test_data).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`engarde` has an awesome set of decorators:\n",
    "\n",
    " - `none_missing` - no NaNs (great for machine learning--sklearn does not care for NaNs)\n",
    " - `has_dtypes` - make sure the dtypes are what you expect\n",
    " - `verify` - runs an arbitrary function on the dataframe\n",
    " - `verify_all` - makes sure every element returns true for a given function\n",
    "\n",
    "More can be found [in the docs](http://engarde.readthedocs.org/en/latest/api.html).\n",
    "\n",
    "**`#lifehack`: test your _data science_ code. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Keep your secrets to yourself \n",
    "\n",
    "We've all seen secrets: passwords, database URLs, API keys checked in to GitHub. Don't do it! Even on a private repo. What's the easiest way to manage these secrets outside of source control? Store them as a `.env` file that lives in your repository, but is not in source control (e.g., add `.env` to your `.gitignore` file).\n",
    "\n",
    "A package called `python-dotenv` manages this for you easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ../.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv(usecwd=True)\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "api_key = os.environ.get(\"API_KEY\")\n",
    "api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Next-level code inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Code coverage\n",
    "\n",
    "`coverage.py` is an _amazing_ tool for seeing what code gets executed when you run your test suite. You can run these commands to generate a code coverage report:\n",
    "\n",
    "    coverage run --source ../src/ ../src/preprocess/tests.py\n",
    "    coverage html\n",
    "    coverage report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"htmlcov/index.html\", 800, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Code profiling\n",
    "\n",
    "Sometimes your code is slow. See which functions are called, how many times, and how long they take!\n",
    "\n",
    "The `%prun` magic reports these to you right in the Jupyter notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mcmc.hamiltonian import hamiltonian, run_diagnostics\n",
    "\n",
    "f = lambda X: np.exp(-100*(np.sqrt(X[:,1]**2 + X[:,0]**2)- 1)**2 + (X[:,0]-1)**3 - X[:,1] - 5)\n",
    "\n",
    "# potential and kinetic energies\n",
    "U = lambda q: -np.log(f(q))\n",
    "K = lambda p: p.dot(p.T) / 2\n",
    "\n",
    "# gradient of the potential energy\n",
    "def grad_U(X):\n",
    "    x, y = X[0,:]\n",
    "\n",
    "    xy_sqrt = np.sqrt(y**2 + x**2)\n",
    "        \n",
    "    mid_term = 100*2*(xy_sqrt - 1) \n",
    "    grad_x = 3*((x-1)**2) - mid_term * ((x) / (xy_sqrt))\n",
    "    grad_y = -1 - mid_term * ((y) / (xy_sqrt))\n",
    "    \n",
    "    return -1*np.array([grad_x, grad_y]).reshape(-1, 2)\n",
    "\n",
    "ham_samples, H = hamiltonian(5000, U, K, grad_U)\n",
    "run_diagnostics(ham_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun ham_samples, H = hamiltonian(5000, U, K, grad_U)\n",
    "run_diagnostics(ham_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 The world beyond Jupyter\n",
    "\n",
    "### Linting and Graphical Debugging (IDEs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[PyCharm](https://www.jetbrains.com/pycharm/download/) is a fully-featured Python IDE. It has _tons_ of integrations with the normal development flow. The features I use most are:\n",
    "\n",
    " - `git` integration\n",
    " - interactive graphical debugger\n",
    " - flake8 linting\n",
    " - smart refactoring/go to"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
